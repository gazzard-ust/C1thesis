# ğŸ¤– MEX3 - Reactive Navigation with YOLOWorld

## ğŸ“‹ Overview

This project implements a reactive navigation system for a TurtleBot using YOLOWorld for real-time object detection and tracking. The system combines computer vision, depth estimation, and autonomous navigation to track and approach specified objects while maintaining safety protocols.

## âœ¨ Features

- **ğŸ‘ï¸ Real-time Object Detection**: Utilizes YOLOWorld for detecting and tracking various objects
- **ğŸ“ Depth Estimation**: Implements depth-anything model for accurate distance calculations
- **ğŸ¯ Reactive Navigation**: Intelligent movement control with centering and approach behaviors
- **ğŸ›¡ï¸ Safety Systems**: Emergency stop capabilities and collision avoidance
- **ğŸŒ Web Interface**: User-friendly web interface for remote control and monitoring
- **ğŸ“¹ Live Video Feed**: Real-time camera and depth visualization
- **ğŸ” Search Behaviors**: Automated 360-degree search patterns when targets are lost

## ğŸ—ï¸ System Architecture

### ğŸ§© Core Components

1. **ğŸ“¸ Image Publisher** (`image_publisher.py`)
   - Captures video from camera (V4L2)
   - Publishes compressed images to ROS topic
   - Handles camera configuration and error recovery

2. **ğŸ§  Image Subscriber** (`image_subscriber.py`)
   - Main navigation controller
   - Object detection using YOLOWorld
   - Depth estimation and distance calculation
   - Movement control and safety systems
   - Web server for user interface

### ğŸ› ï¸ Key Technologies

- **ğŸ”— ROS 2**: Robot Operating System for communication
- **ğŸŒ YOLOWorld**: Open-vocabulary object detection
- **ğŸ“ Depth-Anything**: Monocular depth estimation
- **ğŸ‘€ OpenCV**: Computer vision processing
- **âš¡ FastAPI**: Web interface backend
- **ğŸ”¥ PyTorch**: Deep learning framework

## ğŸ“¦ Installation

### ğŸ“‹ Prerequisites

- ğŸ”§ ROS 2 (Humble/Iron recommended)
- ğŸ Python 3.8+
- ğŸ’» CUDA-capable GPU (recommended)

### ğŸ“š Dependencies

```bash
# Install ROS 2 dependencies
sudo apt install ros-<distro>-cv-bridge ros-<distro>-sensor-msgs

# Install Python packages
pip install torch torchvision ultralytics transformers fastapi uvicorn opencv-python pillow numpy
```

### ğŸ”¨ Build Instructions

```bash
# Clone the repository
git clone https://github.com/SuperMadee/MEX3---Reactive-Navigation-with-YOLOWorld.git
cd MEX3---Reactive-Navigation-with-YOLOWorld

# Build the ROS 2 package
colcon build --packages-select MEx3

# Source the workspace
source install/setup.bash
```

## ğŸš€ Usage

### â–¶ï¸ Running the System

1. **ğŸ“¸ Start the Image Publisher** (Camera Node):
```bash
ros2 run MEx3 image_publisher
```

2. **ğŸ§  Start the Navigation System** (Main Controller):
```bash
ros2 run MEx3 image_subscriber
```

3. **ğŸŒ Access the Web Interface**:
   - Open browser and navigate to `http://localhost:8000`
   - Enter target object name (e.g., "bottle", "chair", "cup")
   - Click "Set Target" to begin tracking

### ğŸ® Web Interface Controls

- **ğŸ¯ Set Target**: Enter object name and start tracking
- **ğŸ”„ Reset**: Clear current target and return to initial state  
- **ğŸ›‘ Emergency Stop**: Immediately halt all robot movement

### ğŸ”Œ API Endpoints

- `GET /set_target?object_name=<name>`: ğŸ¯ Set tracking target
- `GET /reset`: ğŸ”„ Reset system state
- `GET /stop`: ğŸ›‘ Emergency stop
- `GET /robot_status`: ğŸ“Š Get current robot status
- `GET /video_feed`: ğŸ“¹ Live camera feed
- `GET /depth_feed`: ğŸ“ Live depth visualization

## âš™ï¸ Configuration

### ğŸ¤– Robot Parameters

```python
# Safety distances (in cm)
stopping_distance = 30.0
emergency_stop_distance = 20.0
min_safe_distance = 15.0

# Detection parameters
detection_confidence_threshold = 0.15
min_detection_frames = 3

# Movement parameters
max_angular_speed = 0.3
center_tolerance = 30  # pixels
```

### ğŸ“· Camera Settings

```python
# Camera configuration
frame_width = 640
frame_height = 480
fps = 30
focal_length = 525
```

## ğŸ›¡ï¸ Safety Features

- **ğŸ›‘ Emergency Stop**: Immediate halt capability via web interface or API
- **ğŸ“ Distance Monitoring**: Continuous depth-based collision avoidance
- **â° Safety Timeouts**: Automatic stop if no commands received
- **âœ… Detection Stability**: Multiple frame confirmation before movement
- **ğŸŒ Controlled Approach**: Progressive speed reduction near targets

## ğŸ”§ Troubleshooting

### âš ï¸ Common Issues

1. **ğŸ“· Camera Not Found**:
   - Check camera connection and permissions
   - Verify V4L2 device availability: `ls /dev/video*`

2. **ğŸ‘ï¸ No Object Detection**:
   - Ensure adequate lighting
   - Check if object is in YOLOWorld vocabulary
   - Adjust detection confidence threshold

3. **ğŸ¤– Robot Not Moving**:
   - Verify `/cmd_vel` topic is properly connected
   - Check for emergency stop state
   - Ensure target is properly set

### ğŸ› Debug Commands

```bash
# Check ROS topics
ros2 topic list
ros2 topic echo /cmd_vel

# Monitor image stream
ros2 topic echo /image/compressed

# Check node status
ros2 node list
ros2 node info /image_subscriber
```

## ğŸ’» Development

### ğŸ“ File Structure

```
MEx3/
â”œâ”€â”€ MEx3/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ image_publisher.py    # Camera capture and publishing
â”‚   â””â”€â”€ image_subscriber.py   # Main navigation controller
â”œâ”€â”€ package.xml              # ROS package configuration
â”œâ”€â”€ setup.py                # Python package setup
â”œâ”€â”€ setup.cfg               # Package configuration
â””â”€â”€ resource/
    â””â”€â”€ MEx3                # Package resource marker
```

### ğŸ”‘ Key Classes and Methods

#### ğŸ“¸ ImagePublisher
- `publish_image()`: Captures and publishes camera frames
- `destroy_node()`: Cleanup camera resources

#### ğŸ§  ImageSubscriber
- `image_callback()`: Main processing pipeline
- `process_detections()`: Object detection and tracking
- `control_movement()`: Movement control logic
- `search_behavior()`: Target search patterns
- `safety_check()`: Safety monitoring

## ğŸ¤ Contributing

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch
3. âœï¸ Make your changes
4. ğŸ§ª Test thoroughly
5. ğŸ“¤ Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Authors

- **ğŸ‘¨â€ğŸ’» Madee** - Initial development and implementation
- ğŸ“§ Email: mspangaliman@up.edu.ph

## ğŸ™ Acknowledgments

- ğŸŒ YOLOWorld team for open-vocabulary object detection
- ğŸ“ Depth-Anything team for monocular depth estimation
- ğŸ”— ROS 2 community for robotics framework
- ğŸ¤– TurtleBot community for robot platform

## ğŸš€ Future Enhancements

- [ ] ğŸ¯ Multi-object tracking capabilities
- [ ] ğŸ—ºï¸ SLAM integration for mapping
- [ ] ğŸ“ Path planning for complex environments
- [ ] ğŸ“± Mobile app interface
- [ ] ğŸ” Advanced search patterns
- [ ] ğŸ§  Machine learning-based behavior optimization

---

ğŸ“š For more information, visit the [project repository](https://github.com/SuperMadee/MEX3---Reactive-Navigation-with-YOLOWorld).
